{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Categorization using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/dipit/Downloads/bbc-fulltext/bbc/\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root = \"C:/Users/dipit/Downloads/bbc-fulltext/bbc/\"\n",
    "#path = os.path.join(root, \"sample_images\")\n",
    "print(root)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "386\n",
      "417\n",
      "511\n",
      "401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_dt = []\n",
    "count =0\n",
    "title =[]\n",
    "content_type=[]\n",
    "description_1=[]\n",
    "\n",
    "# with open('pagehead.section.htm','r') as f:\n",
    "#     output = f.read()\n",
    "\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    if count==0:\n",
    "        title = subdirs\n",
    "        count = count+1\n",
    "        continue\n",
    "    print(len(files))\n",
    "    for name in files:\n",
    "        content_type.append(title[count-1])\n",
    "        \n",
    "        dest = os.path.join(path,name)\n",
    "        \n",
    "        with open(dest,'r') as f:\n",
    "            output = f.read()\n",
    "            description_1.append(output)\n",
    "        \n",
    "        #print(dest)\n",
    "#     for name in files:\n",
    "#         print name\n",
    "#         list_dt.append(name)\n",
    "    count = count+1\n",
    "\n",
    "#print(title)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225L,)\n",
      "(2225L,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(content_type))\n",
    "print(np.shape(description_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the arrays to dataframe\n",
    "dt_frame = pd.DataFrame({'content_type':content_type,'txt':description_1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       business\n",
       "1       business\n",
       "2       business\n",
       "3       business\n",
       "4       business\n",
       "5       business\n",
       "6       business\n",
       "7       business\n",
       "8       business\n",
       "9       business\n",
       "10      business\n",
       "11      business\n",
       "12      business\n",
       "13      business\n",
       "14      business\n",
       "15      business\n",
       "16      business\n",
       "17      business\n",
       "18      business\n",
       "19      business\n",
       "20      business\n",
       "21      business\n",
       "22      business\n",
       "23      business\n",
       "24      business\n",
       "25      business\n",
       "26      business\n",
       "27      business\n",
       "28      business\n",
       "29      business\n",
       "          ...   \n",
       "2195        tech\n",
       "2196        tech\n",
       "2197        tech\n",
       "2198        tech\n",
       "2199        tech\n",
       "2200        tech\n",
       "2201        tech\n",
       "2202        tech\n",
       "2203        tech\n",
       "2204        tech\n",
       "2205        tech\n",
       "2206        tech\n",
       "2207        tech\n",
       "2208        tech\n",
       "2209        tech\n",
       "2210        tech\n",
       "2211        tech\n",
       "2212        tech\n",
       "2213        tech\n",
       "2214        tech\n",
       "2215        tech\n",
       "2216        tech\n",
       "2217        tech\n",
       "2218        tech\n",
       "2219        tech\n",
       "2220        tech\n",
       "2221        tech\n",
       "2222        tech\n",
       "2223        tech\n",
       "2224        tech\n",
       "Name: content_type, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the content to csv\n",
    "file_name = \"D:/dyp/06 Machine learning/lecture and project/exercise/random forest/new_data/news_data_csv.csv\"\n",
    "dt_frame.to_csv(file_name, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_frame_1 = pd.read_csv(\"D:/dyp/06 Machine learning/lecture and project/exercise/random forest/new_data/news_data_csv.csv\",sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dt_frame_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(dt_frame_1)\n",
    "dt_frame_1.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_type</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content_type                                                txt\n",
       "0     business  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...\n",
       "1     business  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...\n",
       "2     business  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...\n",
       "3     business  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...\n",
       "4     business  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_frame_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/dyp/06 Machine learning/lecture and project/exercise/random forest/new_data/news_data_csv.csv\",sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TFIDF Vectorizer\n",
    "## if not download then download stopwords\n",
    "#nltk.download()\n",
    "#stopset = set[stopwords.words('english')]\n",
    "vectorizer = TfidfVectorizer(use_idf=True, \n",
    "                           lowercase=True,\n",
    "                           strip_accents='ascii',decode_error ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take out dependent variable\n",
    "y = df.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert df.txt from text to features\n",
    "X = vectorizer.fit_transform(df.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225L,)\n",
      "(2225, 29421)\n"
     ]
    }
   ],
   "source": [
    "#check the obserations\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test train split as usual\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test, Train a navive_bayes classifier\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate accuracy using roc\n",
    "\n",
    "#roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sport']\n"
     ]
    }
   ],
   "source": [
    "reviews_arr = np.array([\"Jani score 12 points\"])\n",
    "movie_review_vector = vectorizer.transform(reviews_arr)\n",
    "print clf.predict(movie_review_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
